from sentence_transformers import SentenceTransformer
import numpy as np


# Glossary for vector_search.py

# Vector:
#   An ordered list of numbers representing a point or direction in space.
#   In this program, each vector numerically represents a sentence.

# Embedding:
#   A vector generated by the model that captures the meaning of text
#   in high-dimensional space, allowing semantic comparison.

# SentenceTransformer:
#   The class that loads a pretrained model and converts text into embeddings.

# Model:
#   The trained neural network that maps sentences with similar meanings
#   to nearby vectors in embedding space.

# Normalize:
#   Scaling each embedding so its length (magnitude) equals 1.
#   This focuses comparisons on direction rather than distance.

# Magnitude (or norm):
#   The length of a vector from the origin, calculated as the square root
#   of the sum of squares of its components.

# Cosine similarity:
#   A measure of how close two vectors point in the same direction.
#   1 means identical direction; 0 means unrelated.

# Dot product:
#   The mathematical operation used to compute similarity between vectors.
#   When vectors are normalized, it equals cosine similarity.

# Embedding space:
#   The high-dimensional coordinate system where each sentence is represented as a point.

# Query:
#   The user's input string, also converted to an embedding for comparison
#   with the document embeddings.




#dummy documents list
documents = [
  "The cat sat on the mat.",
  "A dog barked loudly outside",
  "Artificial intelligence is transforming industries",
  "Frank plays piano"
]

#Sentence Transformer invocation with model argument, This model’s internal weights and tokenizer define how text will be turned into embeddings
model = SentenceTransformer("all-MiniLM-L6-v2")

# Encode the list of documents into numerical embeddings (vectors).
# Each document becomes a 384-dimensional vector capturing its meaning.
# The 'normalize_embeddings=True' option scales each vector to length 1,
# so similarity comparisons use direction only (cosine similarity).
# The [0] extracts the first embedding if only one document was passed.
doc_embeddings = model.encode(documents, normalize_embeddings=True)[0]

query = input("Enter your search query: ")

#Embed query
# The model always returns a list or array of embeddings, one for each item in the input list.
# Even if there’s only one item, the output shape is [[v1, v2, v3, ...]] (2D array).
# The [0] extracts the single embedding vector (inner list), giving a 1D array
# that represents the semantic meaning of the query.
query_embedding = model.encode([query], normalize_embeddings=True)[0]




